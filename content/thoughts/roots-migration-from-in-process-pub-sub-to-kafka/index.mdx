---
title: "Root's Migration from In-Process Pub/Sub to Kafka"
description: >-
  An overview of how we migrated from an in-process pub/sub to out-of-process pub/sub with Kafka.
date: 2019-09-16
author: Kyle Thompson
bannerImage: ./images/banner.jpg
bannerCredit: _Photo by [Dimitri Tyan](https://unsplash.com/photos/4FhK9oPCSI0)_
bannerAlt: Logs
categories:
  - programming
  - ruby
  - architecture
keywords:
  - programming
  - ruby
  - architecture
  - kafka
  - rails
published: true
---

import Link from '../../shared/components/external-link';

For a long time at <Link href="https://root.engineering/">Root</Link>, we've used pub/sub as a way to decouple
parts of our application. This was done with a small ruby class. Essentially, you'd call `publish` with an event and
the associated attributes, and any subscribers would run inline at that moment.

That has worked very well for us, but we wanted to have the option to eventually extract some "macroservices" from our
monolith. To make that extraction work, our current pub/sub solution wouldn't quite cut it (since it needs to be able to
call the subscribers directly).

After some investigation into our options (AWS SQS/SNS, AWS Kinesis, RabbitMQ, Redis Pub/Sub, and Kafka), we landed on
Kafka as the successor to our in-process solution. In this post, I'm going to dive into what our existing solution
looked like, and how we migrated to Kafka without any downtime.

# Our in-process pub/sub implementation

Let's start this off with some code. This is a small example of how you might use our in-process pub/sub:

```ruby
# engines/profiles/config/initializers/pub_sub.rb

PROFILES_PUB_SUB = PubSub.new

PROFILES_PUB_SUB.register(:profile_updated, attributes: %i[account_id profile_id])

# engines/profiles/app/services/profile_service.rb

module ProfileService
  def self.update(account_id:, profile_attributes:)
    # ...
    PROFILES_PUB_SUB.publish(:profile_updated, account_id: account_id, profile_id: profile_id)
  end
end

# engines/rating/config/initializers/pub_sub.rb

PROFILES_PUB_SUB.subscribe(:profile_updated) do |account_id:, profile_id:|
  RateJob.perform_later(account_id: account_id, profile_id: profile_id)
end
```

In this example, we have an instance of `PubSub` with one event (`:profile_updated`) that takes `account_id` and
`profile_id` as attributes. Once the profile is updated in the `ProfileService`, `:profile_updated` is published to the
`PROFILES_PUB_SUB`. Finally, `RateJob` is subscribed to the `:profile_updated` event in the `rating` engine.

One minor thing to note here is the use of "engines." For a little more information on how we have structured our Rails
application, check out <Link href="https://medium.com/@dan_manges/the-modular-monolith-rails-architecture-fb1023826fc4/">our CTO's blog post about the modular monolith.</Link>

Anyway, a slimmed down implementation of the `PubSub` class looks roughly like this:

```ruby
class PubSub
  Event = Struct.new(:name, :attributes, :subscribers)

  def initialize
    @events = {}
  end

  def register(event_name, attributes:)
    event = Event.new(event_name, attributes, [])
    events[event_name] = event
  end

  def publish(event_name, attributes = {})
    event = events.fetch(event_name)
    raise "invalid event" unless attributes.keys.to_set == event.attributes.to_set

    event.subscribers.each do |subscriber|
      subscriber.call(attributes)
    end
  end

  def subscribe(event_name, &block)
    event = events.fetch(event_name)
    raise "invalid subscriber" unless block.parameters.all? { |type, _name| type == "keyreq" }
    raise "invalid subscriber" unless block.parameters.map { |_type, name| name }.to_set == event.attributes.to_set

    event.subscribers << block
  end

  private

  attr_reader :events
end
```

As mentioned earlier, when we "publish" an event all of the subscribers are executed inline.

# Our migration to Kafka

Within our system, we have a good amount of business critical functionality running through our pub/sub setup. Up to
this point, that wasn't a point of concern as it was just another piece of code executing. Moving to Kafka introduces
another point of failure with a distributed system, so we had to de-risk our migration. To do so, we gathered data and
took an incremental approach in cutting over.

## Gathering analytics

To fully understand the load we would be putting on this new system, we started by gathering data on our current usage
of pub/sub. Primarily, we were interested (at this point) in how many messages per second we were consuming per
anticipated topic.

To get these metrics, we instrumented the existing pub/sub code with counts through StatsD. We used these metrics to do
some capacity planning for our Kafka cluster.

## Publishing and consuming messages (no-op)

We didn't want to jump right into publishing and consuming pub/sub through Kafka (even with our analytics). Since we
hadn't run a Kafka cluster in production yet, we wanted to be sure we understood how it would behave. To get ourselves
more comfortable with it, we started with consumers that would no-op and simply mark messages as consumed. Since the
consumers weren't doing any work, we also had to support publishing to both Kafka and our inline subscribers at the same
time.

As one final bit of precaution, we also set the Kafka publisher up to have a chance-based publish to limit throughput
(adjustable through an environment variable) and started publishing only in our background workers. After slowly scaling
up to 100% publish chance in background workers and getting a good idea of the differences in timing to publish, we
turned publishing to Kafka on in the web workers (again, slowly scaling up the publish chance).

## Cutting over fully to publishing and consuming in Kafka

After letting the no-op implementation settle, we included additional metadata in our messages to Kafka to indicate
whether the consumer should process the message. This value was controlled through an environment variable, so we could
switch between in-process pub/sub and Kafka if necessary.

Now that we were confident in publishing and consuming, we were able to cutover the environment variable to consume
messages in our Kafka consumers. When this environment variable was changed, we stopped publishing to the inline
subscribers and were only publishing to Kafka.
